import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
from itertools import product
import itertools
# from GroupInfo import GroupInfo, GroupsInfo
import geatpy as ea


# from geatpy.zqq.Run_metric import Alg_Evaluation

# def Evaluate(actual, pred):
#     confusion = pd.crosstab(actual, pred, rownames=['Actual'], colnames=['Predicted'])
#     TP = confusion.loc['>50K', '>50K']
#     TN = confusion.loc['<=50K', '<=50K']
#     FP = confusion.loc['<=50K', '>50K']
#     FN = confusion.loc['>50K', '<=50K']
#
#     accuracy = ((TP + TN)) / (TP + FN + FP + TN)
#     precision = (TP) / (TP + FP)
#     recall = (TP) / (TP + FN)
#     f_measure = (2 * recall * precision) / (recall + precision)
#     sensitivity = TP / (TP + FN)
#     specificity = TN / (TN + FP)
#     error_rate = 1 - accuracy
#
#     out = {}
#     out['accuracy'] = accuracy
#     out['precision'] = precision
#     out['recall'] = recall
#     out['f_measure'] = f_measure
#     out['sensitivity'] = sensitivity
#     out['specificity'] = specificity
#     out['error_rate'] = error_rate
#
#     return out


def DemographicParity_EqualizedOdds3(data, logits, truelabel, sensitive_attributions):
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"
    # a few differences: "logits - truelabel + 1" instead on "pred_label - truelabel + 1"
    sum_num = logits.shape[0] * logits.shape[1]

    pred_label = get_label(logits.copy())
    accuracy = np.sum(pred_label == truelabel) / sum_num
    MSE = np.mean(np.power(logits - truelabel, 2))

    attribution = data.columns
    DemographicParity = 0.0
    EqualizedOdds = 0.0
    group_dict = {}
    Groups = []

    for sens in sensitive_attributions:
        temp = []
        for attr in attribution:
            temp1 = sens + '_'
            if temp1 in attr:
                temp.append(attr)
        group_dict.update({sens: temp})

    group_attr = []
    groups_total_inD = []  # 计算 Demographic Parity 的每个组的个数
    groups_pred1_inD = []  # 计算 Demographic Parity 中每个组预测为1的个数

    groups_total_is1_inE = []  # 计算 Equalized Odds 中每个组真实为1的个数
    groups_total_is0_inE = []  # 计算 Equalized Odds 中每个组真实为0的个数
    groups_true1_pred1_inE = []  # 计算 Equalized Odds 中每个组真实为1，预测为1的个数
    groups_true0_pred1_inE = []  # 计算 Equalized Odds 中每个组预测为0，预测为1的个数
    groups_pred1val_inD = []
    groups_total_is1val_inE = []
    groups_total_is0val_inE = []
    groups_true1_pred1val_inE = []
    groups_true0_pred1val_inE = []

    for sens in sensitive_attributions:
        group = group_dict[sens]
        groups_total_inD_temp = []
        groups_pred1val_inD_temp = []
        groups_pred1_inD_temp = []
        groups_total_is1_inE_temp = []
        groups_total_is0_inE_temp = []
        groups_true1_pred1_inE_temp = []
        groups_true0_pred1_inE_temp = []
        groups_total_is1val_inE_temp = []
        groups_total_is0val_inE_temp = []
        groups_true1_pred1val_inE_temp = []
        groups_true0_pred1val_inE_temp = []
        for g in group:
            flag = np.ones([1, sum_num]) == np.ones([1, sum_num])
            flag = flag & data[g]
            g_num = np.sum(flag)
            if g_num != 0:
                flag_pred1 = flag & (pred_label[0, :] == 1)  # 小组g中，被预测为1的flag

                flag_true1 = flag & (truelabel == 1)  # 小组g中，真实标签为1的flag
                flag_true0 = flag & (truelabel == 0)  # 小组g中，真实标签为0的flag

                flag_true1_pred1 = flag_true1 & (pred_label == 1)  # 小组g中，真实标签为1，预测也为1的flag
                flag_true0_pred1 = flag_true0 & (pred_label == 1)  # 小组g中，真实标签为0，预测为1的flag

                # record Demographic Parity
                groups_total_inD_temp.append(np.sum(flag))
                groups_pred1val_inD_temp.append(np.sum(np.power(logits[0, np.where(flag_pred1.values)], 2)))
                groups_pred1_inD_temp.append(np.sum(flag_pred1))

                # record Equalized Odds
                groups_total_is1_inE_temp.append(np.sum(flag_true1))
                groups_total_is0_inE_temp.append(np.sum(flag_true0))
                groups_true1_pred1_inE_temp.append(np.sum(flag_true1_pred1))
                groups_true0_pred1_inE_temp.append(np.sum(flag_true0_pred1))

                groups_total_is1val_inE_temp.append(np.sum(np.power(logits[0, np.where(flag_true1.values)], 2)))
                groups_total_is0val_inE_temp.append(np.sum(np.power(logits[0, np.where(flag_true0.values)], 2)))
                groups_true1_pred1val_inE_temp.append(np.sum(np.power(logits[0, np.where(flag_true1_pred1.values)], 2)))
                groups_true0_pred1val_inE_temp.append(np.sum(np.power(logits[0, np.where(flag_true0_pred1.values)], 2)))

        groups_total_inD.append(groups_total_inD_temp)
        groups_pred1val_inD.append(groups_pred1val_inD_temp)
        groups_pred1_inD.append(groups_pred1_inD_temp)

        # record Equalized Odds
        groups_total_is1_inE.append(groups_total_is1_inE_temp)
        groups_total_is0_inE.append(groups_total_is0_inE_temp)
        groups_true1_pred1_inE.append(groups_true1_pred1_inE_temp)
        groups_true0_pred1_inE.append(groups_true0_pred1_inE_temp)

        groups_total_is1val_inE.append(groups_total_is1val_inE_temp)
        groups_total_is0val_inE.append(groups_total_is0val_inE_temp)
        groups_true1_pred1val_inE.append(groups_true1_pred1val_inE_temp)
        groups_true0_pred1val_inE.append(groups_true0_pred1val_inE_temp)


    groups_total_inD = np.array(groups_total_inD)
    groups_pred1_inD = np.array(groups_pred1_inD)
    groups_pred1val_inD = np.array(groups_pred1val_inD)

    groups_total_is1_inE = np.array(groups_total_is1_inE)
    groups_total_is0_inE = np.array(groups_total_is0_inE)
    groups_true1_pred1_inE = np.array(groups_true1_pred1_inE)
    groups_true0_pred1_inE = np.array(groups_true0_pred1_inE)

    groups_total_is1val_inE = np.array(groups_total_is1val_inE)
    groups_total_is0val_inE = np.array(groups_total_is0val_inE)
    groups_true1_pred1val_inE = np.array(groups_true1_pred1val_inE)
    groups_true0_pred1val_inE = np.array(groups_true0_pred1val_inE)

    is_propor = 0
    # calculate Demographic Parity
    pro_D = groups_pred1_inD / groups_total_inD
    # pro_D = groups_pred1val_inD / groups_total_inD
    mean_D = np.mean(pro_D, axis=1)
    proportial = groups_total_inD / np.sum(groups_total_inD)
    if is_propor == 1:
        DemographicParity = np.sum(np.abs(pro_D - mean_D.reshape(-1, 1)) * proportial)
    else:
        DemographicParity = np.sum(np.abs(pro_D - mean_D).reshape(-1, 1))

    # record Equalized Odds
    pro_E1 = groups_true1_pred1_inE / groups_total_is1_inE
    # pro_E1 = groups_true1_pred1val_inE / groups_total_is1_inE
    mean_E1 = np.mean(pro_E1, axis=1)
    proportial1 = groups_total_is1_inE / np.sum(groups_total_is1_inE)
    if is_propor == 1:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1.reshape(-1, 1)) * proportial1)
    else:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1.reshape(-1, 1)))

    pro_E2 = groups_true0_pred1_inE / groups_total_is0_inE
    # pro_E2 = groups_true0_pred1val_inE / groups_total_is0_inE
    mean_E2 = np.mean(pro_E2, axis=1)
    proportial2 = groups_total_is0_inE / np.sum(groups_total_is0_inE)
    if is_propor == 1:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2.reshape(-1, 1)) * proportial2)
    else:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2.reshape(-1, 1)))

    EqualizedOdds = (EqualizedOdds1 + EqualizedOdds2) / 2

    Groups_info = []
    return accuracy, MSE, DemographicParity * 100, EqualizedOdds * 100, Groups_info


def DemographicParity_EqualizedOdds2(data, logits, truelabel, sensitive_attributions):
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"
    # a few differences: "logits - truelabel + 1" instead on "pred_label - truelabel + 1"
    sum_num = logits.shape[0] * logits.shape[1]

    pred_label = get_label(logits.copy())
    accuracy = np.sum(pred_label == truelabel) / sum_num
    MSE = np.mean(np.power(logits - truelabel, 2))

    attribution = data.columns
    DemographicParity = 0.0
    EqualizedOdds = 0.0
    group_dict = {}
    Groups = []

    for sens in sensitive_attributions:
        temp = []
        for attr in attribution:
            temp1 = sens + '_'
            if temp1 in attr:
                temp.append(attr)
        group_dict.update({sens: temp})

    group_attr = []
    groups_total_inD = []  # 计算 Demographic Parity 的每个组的个数
    groups_pred1_inD = []  # 计算 Demographic Parity 中每个组预测为1的个数

    groups_total_is1_inE = []  # 计算 Equalized Odds 中每个组真实为1的个数
    groups_total_is0_inE = []  # 计算 Equalized Odds 中每个组真实为0的个数
    groups_true1_pred1_inE = []  # 计算 Equalized Odds 中每个组真实为1，预测为1的个数
    groups_true0_pred1_inE = []  # 计算 Equalized Odds 中每个组预测为0，预测为1的个数
    groups_pred1val_inD = []
    groups_total_is1val_inE = []
    groups_total_is0val_inE = []
    groups_true1_pred1val_inE = []
    groups_true0_pred1val_inE = []

    for sens in sensitive_attributions:
        group_attr.append(group_dict[sens])
    for item in product(*eval(str(group_attr))):
        group = item
        flag = np.ones([1, sum_num]) == np.ones([1, sum_num])
        for g in group:
            flag = flag & data[g]
        g_num = np.sum(flag)
        if g_num != 0:
            flag_pred1 = flag & (pred_label[0, :] == 1)  # 小组g中，被预测为1的flag

            flag_true1 = flag & (truelabel == 1)  # 小组g中，真实标签为1的flag
            flag_true0 = flag & (truelabel == 0)  # 小组g中，真实标签为0的flag

            flag_true1_pred1 = flag_true1 & (pred_label == 1)  # 小组g中，真实标签为1，预测也为1的flag
            flag_true0_pred1 = flag_true0 & (pred_label == 1)  # 小组g中，真实标签为0，预测为1的flag

            # record Demographic Parity
            groups_total_inD.append(np.sum(flag))
            groups_pred1val_inD.append(np.sum(np.power(logits[0, np.where(flag_pred1.values)], 2)))
            groups_pred1_inD.append(np.sum(flag_pred1))

            # record Equalized Odds
            groups_total_is1_inE.append(np.sum(flag_true1))
            groups_total_is0_inE.append(np.sum(flag_true0))
            groups_true1_pred1_inE.append(np.sum(flag_true1_pred1))
            groups_true0_pred1_inE.append(np.sum(flag_true0_pred1))

            groups_total_is1val_inE.append(np.sum(np.power(logits[0, np.where(flag_true1.values)], 2)))
            groups_total_is0val_inE.append(np.sum(np.power(logits[0, np.where(flag_true0.values)], 2)))
            groups_true1_pred1val_inE.append(np.sum(np.power(logits[0, np.where(flag_true1_pred1.values)], 2)))
            groups_true0_pred1val_inE.append(np.sum(np.power(logits[0, np.where(flag_true0_pred1.values)], 2)))

    groups_total_inD = np.array(groups_total_inD)
    groups_pred1_inD = np.array(groups_pred1_inD)
    groups_pred1val_inD = np.array(groups_pred1val_inD)

    groups_total_is1_inE = np.array(groups_total_is1_inE)
    groups_total_is0_inE = np.array(groups_total_is0_inE)
    groups_true1_pred1_inE = np.array(groups_true1_pred1_inE)
    groups_true0_pred1_inE = np.array(groups_true0_pred1_inE)

    groups_total_is1val_inE = np.array(groups_total_is1val_inE)
    groups_total_is0val_inE = np.array(groups_total_is0val_inE)
    groups_true1_pred1val_inE = np.array(groups_true1_pred1val_inE)
    groups_true0_pred1val_inE = np.array(groups_true0_pred1val_inE)

    is_propor = 0
    # calculate Demographic Parity
    # pro_D = groups_pred1_inD / groups_total_inD
    pro_D = groups_pred1val_inD / groups_total_inD
    mean_D = np.mean(pro_D)
    proportial = groups_total_inD / np.sum(groups_total_inD)
    if is_propor == 1:
        DemographicParity = np.sum(np.abs(pro_D - mean_D) * proportial)
    else:
        DemographicParity = np.sum(np.abs(pro_D - mean_D))

    # record Equalized Odds
    # pro_E1 = groups_true1_pred1_inE / groups_total_is1_inE
    pro_E1 = groups_true1_pred1val_inE / groups_total_is1_inE
    mean_E1 = np.mean(pro_E1)
    proportial1 = groups_total_is1_inE / np.sum(groups_total_is1_inE)
    if is_propor == 1:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1) * proportial1)
    else:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1))

    # pro_E2 = groups_true0_pred1_inE / groups_total_is0_inE
    pro_E2 = groups_true0_pred1val_inE / groups_total_is0_inE
    mean_E2 = np.mean(pro_E2)
    proportial2 = groups_total_is0_inE / np.sum(groups_total_is0_inE)
    if is_propor == 1:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2) * proportial2)
    else:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2))

    EqualizedOdds = (EqualizedOdds1 + EqualizedOdds2) / 2

    Groups_info = []
    return accuracy, MSE, DemographicParity * 100, EqualizedOdds * 100, Groups_info


def DemographicParity_EqualizedOdds(data, logits, truelabel, sensitive_attributions):
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"
    # a few differences: "logits - truelabel + 1" instead on "pred_label - truelabel + 1"
    sum_num = logits.shape[0] * logits.shape[1]

    pred_label = get_label(logits.copy())
    accuracy = np.sum(pred_label == truelabel) / sum_num
    MSE = np.mean(np.power(logits - truelabel, 2))

    attribution = data.columns
    DemographicParity = 0.0
    EqualizedOdds = 0.0
    group_dict = {}
    Groups = []

    for sens in sensitive_attributions:
        temp = []
        for attr in attribution:
            temp1 = sens + '_'
            if temp1 in attr:
                temp.append(attr)
        group_dict.update({sens: temp})

    group_attr = []
    groups_total_inD = []  # 计算 Demographic Parity 的每个组的个数
    groups_pred1_inD = []  # 计算 Demographic Parity 中每个组预测为1的个数

    groups_total_is1_inE = []  # 计算 Equalized Odds 中每个组真实为1的个数
    groups_total_is0_inE = []  # 计算 Equalized Odds 中每个组真实为0的个数
    groups_true1_pred1_inE = []  # 计算 Equalized Odds 中每个组真实为1，预测为1的个数
    groups_true0_pred1_inE = []  # 计算 Equalized Odds 中每个组预测为0，预测为1的个数

    for sens in sensitive_attributions:
        group_attr.append(group_dict[sens])
    for item in product(*eval(str(group_attr))):
        group = item
        flag = np.ones([1, sum_num]) == np.ones([1, sum_num])
        for g in group:
            flag = flag & data[g]
        g_num = np.sum(flag)
        if g_num != 0:
            flag_pred1 = flag & (pred_label[0, :] == 1)  # 小组g中，被预测为1的flag

            flag_true1 = flag & (truelabel == 1)  # 小组g中，真实标签为1的flag
            flag_true0 = flag & (truelabel == 0)  # 小组g中，真实标签为0的flag

            flag_true1_pred1 = flag_true1 & (pred_label == 1)  # 小组g中，真实标签为1，预测也为1的flag
            flag_true0_pred1 = flag_true0 & (pred_label == 1)  # 小组g中，真实标签为0，预测为1的flag

            # record Demographic Parity
            groups_total_inD.append(np.sum(flag))
            groups_pred1_inD.append(np.sum(flag_pred1))

            # record Equalized Odds
            groups_total_is1_inE.append(np.sum(flag_true1))
            groups_total_is0_inE.append(np.sum(flag_true0))
            groups_true1_pred1_inE.append(np.sum(flag_true1_pred1))
            groups_true0_pred1_inE.append(np.sum(flag_true0_pred1))
    groups_total_inD = np.array(groups_total_inD)
    groups_pred1_inD = np.array(groups_pred1_inD)
    groups_total_is1_inE = np.array(groups_total_is1_inE)
    groups_total_is0_inE = np.array(groups_total_is0_inE)
    groups_true1_pred1_inE = np.array(groups_true1_pred1_inE)
    groups_true0_pred1_inE = np.array(groups_true0_pred1_inE)

    is_propor = 0
    # calculate Demographic Parity
    pro_D = groups_pred1_inD / groups_total_inD
    mean_D = np.mean(pro_D)
    proportial = groups_total_inD / np.sum(groups_total_inD)
    if is_propor == 1:
        DemographicParity = np.sum(np.abs(pro_D - mean_D) * proportial)
    else:
        DemographicParity = np.sum(np.abs(pro_D - mean_D))

    # record Equalized Odds
    pro_E1 = groups_true1_pred1_inE / groups_total_is1_inE
    mean_E1 = np.mean(pro_E1)
    proportial1 = groups_total_is1_inE / np.sum(groups_total_is1_inE)
    if is_propor == 1:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1) * proportial1)
    else:
        EqualizedOdds1 = np.sum(np.abs(pro_E1 - mean_E1))

    pro_E2 = groups_true0_pred1_inE / groups_total_is0_inE
    mean_E2 = np.mean(pro_E2)
    proportial2 = groups_total_is0_inE / np.sum(groups_total_is0_inE)
    if is_propor == 1:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2) * proportial2)
    else:
        EqualizedOdds2 = np.sum(np.abs(pro_E2 - mean_E2))

    EqualizedOdds = (EqualizedOdds1 + EqualizedOdds2) / 2

    Groups_info = []
    return accuracy, MSE, DemographicParity * 100, EqualizedOdds * 100, Groups_info


def get_label(logits):
    pred_label = logits
    pred_label[np.where(pred_label >= 0.5)] = 1
    pred_label[np.where(pred_label < 0.5)] = 0
    pred_label = pred_label.reshape(1, logits.shape[0] * logits.shape[1])
    pred_label = pred_label.reshape(1, -1)
    return pred_label


def calcul_indivi(benefits, alpha):
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"

    num = benefits.shape[0] * benefits.shape[1]
    mu = np.mean(benefits)
    # individual_fitness = np.sum(np.power(benefits/mu, alpha)-1)/(num*(alpha-1)*alpha)
    individual_fitness = np.sum(np.power(benefits / mu, alpha) - 1) / (num * (alpha - 1) * alpha)
    return individual_fitness


def calcul_all_fairness(data, logits, truelabel, sensitive_attributions, alpha):
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"
    # a few differences: "logits - truelabel + 1" instead on "pred_label - truelabel + 1"
    sum_num = logits.shape[0] * logits.shape[1]

    pred_label = get_label(logits.copy())
    # benefits = pred_label - truelabel + 1   # original version
    benefits = logits - truelabel + 1  # new version in section 3.1
    benefits_mean = np.mean(benefits)
    accuracy = np.sum(pred_label == truelabel) / sum_num

    attribution = data.columns
    Individual_fairness = 0.0
    Group_fairness = 0.0
    group_dict = {}
    Groups = []

    for sens in sensitive_attributions:
        temp = []
        for attr in attribution:
            temp1 = sens + '_'
            if temp1 in attr:
                temp.append(attr)
        group_dict.update({sens: temp})

    group_attr = []
    for sens in sensitive_attributions:
        group_attr.append(group_dict[sens])
    for item in product(*eval(str(group_attr))):
        group = item
        flag = np.ones([1, sum_num]) == np.ones([1, sum_num])
        for g in group:
            flag = flag & data[g]
        g_num = np.sum(flag)
        if g_num != 0:
            g_idx = np.array(np.where(flag)).reshape([1, g_num])
            g_logits = logits[0, g_idx].reshape([1, g_num])
            g_pred_label = pred_label[0, g_idx].reshape([1, g_num])
            g_true_label = truelabel[0, g_idx].reshape([1, g_num])
            g_benefits = benefits[0, g_idx].reshape([1, g_num])
            g_fairness = calcul_indivi(g_benefits, alpha)
            g_benefits_mean = np.mean(g_benefits)
            g_individual_fairness = (g_num / sum_num) * (np.power(g_benefits_mean / benefits_mean, alpha)) * g_fairness
            g_group_fairness = (g_num / (sum_num * (alpha - 1) * alpha)) * (
                    np.power(g_benefits_mean / benefits_mean, alpha) - 1)
            Individual_fairness += g_individual_fairness
            Group_fairness += g_group_fairness
            g = ea.GroupInfo(group, g_group_fairness, g_individual_fairness, g_true_label, g_pred_label, g_logits,
                             sum_num)
            # Groups.append(g)
        # print('In the', item, ':')
        # print('Accuracy: %.4f, Individual fairness: %.4f, Group fairness: %.4f' % (g.getAccuracy(), g_individual_fairness
        #       , g_group_fairness))
    accuracy_loss = np.mean(np.power(benefits - 1, 2))
    Groups_info = ea.GroupsInfo(Groups)
    return accuracy, accuracy_loss, Individual_fairness, Group_fairness, Groups_info


def generalized_entropy_index(logits, truelabel, alpha):
    # https://github.com/Trusted-AI/AIF360/blob/master/aif360/metrics/classification_metric.py#L664
    pred_label = get_label(logits.copy())
    # benefits = pred_label - truelabel + 1  # original version
    benefits = logits - truelabel + 1  # new version in section 3.1
    b = benefits
    if alpha == 1:
        # moving the b inside the log allows for 0 values
        return np.mean(np.log((b / np.mean(b)) ** b) / np.mean(b))
    elif alpha == 0:
        return -np.mean(np.log(b / np.mean(b)) / np.mean(b))
    else:
        return np.mean((b / np.mean(b)) ** alpha - 1) / (alpha * (alpha - 1))


def between_all_groups_generalized_entropy_index(data, logits, truelabel, sensitive_attributions, alpha):
    # https://github.com/Trusted-AI/AIF360/blob/master/aif360/metrics/classification_metric.py#L700
    # The method is from "Unified Approach to Quantifying Algorithmic Unfairness:
    # Measuring Individual & Group Unfairness via Inequality Indices"
    sum_num = logits.shape[0] * logits.shape[1]

    pred_label = get_label(logits.copy())
    # benefits = pred_label - truelabel + 1   # original version
    benefits = logits - truelabel + 1  # new version in section 3.1
    attribution = data.columns
    group_dict = {}
    b = np.zeros(sum_num, dtype=np.float64)

    for sens in sensitive_attributions:
        temp = []
        for attr in attribution:
            temp1 = sens + '_'
            if temp1 in attr:
                temp.append(attr)
        group_dict.update({sens: temp})

    group_attr = []
    for sens in sensitive_attributions:
        group_attr.append(group_dict[sens])
    for item in product(*eval(str(group_attr))):
        group = item
        flag = np.ones([1, sum_num]) == np.ones([1, sum_num])
        for g in group:
            flag = flag & data[g]
        g_num = np.sum(flag)
        if g_num != 0:
            g_idx = np.array(np.where(flag)).reshape([1, g_num])
            b[g_idx] = np.mean(benefits[0, g_idx].reshape([1, g_num]))

    return calcul_indivi(b.reshape([1, -1]), alpha)


def Cal_objectives(data, data_norm, logits, truelabel, sensitive_attributions, alpha):
    sum_num = logits.shape[0] * logits.shape[1]
    logits = np.array(logits).reshape([1, sum_num])
    truelabel = np.array(truelabel).reshape([1, sum_num])
    pred_label = get_label(logits.copy())
    # print(generalized_entropy_index(logits, truelabel, alpha))
    # print( between_all_groups_generalized_entropy_index(data, logits, truelabel, sensitive_attributions, alpha))
    plan = 1
    if plan == 1:
        accuracy, accuracy_loss, Individual_fairness, Group_fairness, Groups_info = calcul_all_fairness(data,
                                                                                                        logits,
                                                                                                        truelabel,
                                                                                                        sensitive_attributions,
                                                                                                        alpha)
    else:
        accuracy, accuracy_loss, Individual_fairness, Group_fairness, Groups_info = DemographicParity_EqualizedOdds3(
            data,
            logits,
            truelabel,
            sensitive_attributions)

    return accuracy, accuracy_loss, Individual_fairness, Group_fairness, Groups_info
