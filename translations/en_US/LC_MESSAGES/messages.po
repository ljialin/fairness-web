# English (United States) translations for PROJECT.
# Copyright (C) 2021 ORGANIZATION
# This file is distributed under the same license as the PROJECT project.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
"POT-Creation-Date: 2022-01-17 19:00+0800\n"
"PO-Revision-Date: 2021-12-27 11:32+0800\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: en_US\n"
"Language-Team: en_US <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

# pybabel compile -d translations

#: app.py:134 app.py:175 templates/data_eval.html:51
#: templates/data_eval.html:75 templates/model_eval.html:51
#: templates/model_eval.html:74
msgid "group_fairness_analysis"
msgstr "Group fairness analysis"

#: app.py:136 templates/data_eval.html:70 templates/data_eval.html:99
msgid "individual_fariness_analysis"
msgstr "Individual fairness analysis"

#: app.py:138 app.py:177 templates/data_eval.html:69
#: templates/data_eval.html:87 templates/model_eval.html:69
#: templates/model_eval.html:86
msgid "conditional_group_fairness_analysis"
msgstr "Conditional group fairness analysis"

#: app.py:217 templates/algo_cfg.html:90
msgid "upload_init_models"
msgstr "Upload initialization models"

#: src/common_fair_analyze.py:39
msgid "model_chart_1"
msgstr ""
"Ratio of group positive label rate between overall and groups divided by "
"this legitimate attribute"

#: src/mvc/algo_cfg.py:103
msgid "task_error1"
msgstr "Population size must be digital"

#: src/mvc/algo_cfg.py:108
msgid "task_error2"
msgstr "Generation number must be digital"

#: src/mvc/algo_cfg.py:115
msgid "task_error3"
msgstr "Continuous attributes are not supported as sensitive attributes"

#: src/mvc/algo_cfg.py:176
msgid "progress_info_1"
msgstr "Evolving ... generation {}/{}({}%) "

#: src/mvc/algo_cfg.py:181
msgid "progress_info_2"
msgstr "Initializing problem instances ..."

#: src/mvc/algo_cfg.py:183
msgid "progress_info_3"
msgstr "Initializing population"

#: src/mvc/algo_cfg.py:185
msgid "progress_info_4"
msgstr "Initializing parameters ..."

#: src/mvc/algo_cfg.py:187
msgid "progress_info_5"
msgstr "Evolution finished!"

#: src/mvc/algo_cfg.py:194
msgid "progress_info_6"
msgstr "Task stop! generation{}/{}({}%)"

#: src/mvc/data.py:74
msgid "label_error"
msgstr "Label can only contain two different values"

#: src/mvc/data.py:93
msgid "update_error"
msgstr "The format of dataset is incorrect, please check by reading template file"

#: src/mvc/data.py:343
msgid "filename_conflict"
msgstr "Filename conflict"

#: src/mvc/data.py:349
msgid "dataset_duplicate_name"
msgstr ""
"Upload fail: The name of uploaded dataset is same to the datasets already"
" exsit"

#: src/mvc/data_eval.py:63
msgid "data_eval_result_1"
msgstr ""
"The positive label (label={}) rate of \"{}\" group is lower than the "
"positive label rate of whole dataset. It is recommended to check whether "
"the group is discriminated \\ preferenced, and this attribute should be "
"non-sensitive attribute which influences the result."

#: src/mvc/data_eval.py:65
msgid "data_eval_result_2"
msgstr ""
"The positive label (label={}) rate of \"{}\" group is higher than the "
"positive label rate of whole dataset. It is recommended to check whether "
"the group is discriminated \\ preferenced, and this attribute should be "
"non-sensitive attribute which influences the result."

#: src/mvc/data_eval.py:67
msgid "data_eval_result_4"
msgstr ""
"No fairness issue was found in group fairness analysis for sensitive "
"attribute \"{}\""

#: src/mvc/data_eval.py:121
msgid "data_eval_result_6"
msgstr ""
"The radio of positive label rate between the subgroup \"{}\"=\"{}\" of "
"group \"{}\"=\"{}\" and the whole group (positive label: \"{}\"=\"{}\") is "
"low, this group may be discriminated \\ preferenced."

#: src/mvc/data_eval.py:126
msgid "data_eval_result_7"
msgstr ""
"The radio of positive label rate between the subgroup \"{}\"=\"{}\" of "
"group \"{}\"=\"{}\" and the whole group (positive label: \"{}\"=\"{}\") is "
"high, this group may be discriminated \\ preferenced."

#: src/mvc/data_eval.py:131
msgid "data_eval_result_11"
msgstr ""
"After using \"{}\" as the legitimate attribute to analyse the attribute "
"\"{}\", no fairness issue was found."

#: src/mvc/data_eval.py:152
msgid "data_eval_result_8"
msgstr ""
"After analysing the legitimate attribute \"{}\", the following \"{}\" "
"individuals may be discriminated \\ preferenced: "

#: src/mvc/data_eval.py:159
msgid "data_eval_result_5"
msgstr "No fairness problems were found in the current dataset"

#: src/mvc/data_eval.py:249
msgid "data_eval_result_9"
msgstr "The analysis result of attribute \"{}\""

#: src/mvc/data_eval.py:251
msgid "data_eval_result_10"
msgstr "The group partitioned by \"{}\""

#: src/mvc/data_eval.py:262
msgid "data_chart_1"
msgstr "Ratio of group positive label rate to overall positive label rate"

#: src/mvc/data_eval.py:308
msgid "data_eval_error_1"
msgstr "At least one sensitive attribute must be selected for analysis"

#: src/mvc/data_eval.py:315
msgid "data_eval_error_2"
msgstr ""
"At least one sensitive attribute and one legitimate attribute must be "
"selected for analysis"

#: src/mvc/data_eval.py:317
msgid "data_eval_error_3"
msgstr "Legitimate attributes must be non-sensitive attributes"

#: src/mvc/data_eval.py:324
msgid "data_eval_error_4"
msgstr "At least one legitimate attribute must be selected for analysis"

#: src/mvc/model_eval.py:96 src/mvc/model_eval.py:108
msgid "model_eval_result_2"
msgstr "No fairness issue was found in the analysis of \"{}\""

#: src/mvc/model_eval.py:139
msgid "model_eval_result_3"
msgstr ""
"The radio of positive prediction rate between the subgroup \"{}\"=\"{}\" "
"of group \"{}\"=\"{}\" and the whole group (positive label: \"{}\"=\"{}\") "
"is low, this group may be discriminated \\ preferenced."

#: src/mvc/model_eval.py:141
msgid "model_eval_result_4"
msgstr ""
"The radio of positive prediction rate between the subgroup \"{}\"=\"{}\" "
"of group \"{}\"=\"{}\" and the whole group (positive label: \"{}\"=\"{}\") "
"is high, this group may be discriminated \\ preferenced."

#: src/mvc/model_eval.py:143
msgid "model_eval_result_5 "
msgstr ""
"After using \"{}\" as the legitimate attribute to analyse the attribute "
"\"{}\", no fairness issue was found."

#: src/mvc/model_eval.py:155 src/mvc/model_eval.py:158
msgid "discrimination_preference"
msgstr "discriminated \\ preferenced"

#: src/mvc/model_eval.py:159
msgid "and_eo"
msgstr " and Equalized Odds"

#: src/mvc/model_eval.py:162
msgid "model_eval_result_1"
msgstr ""
"According to \"{}\", group \"{}\" may be \"{}\". It is suggested to "
"consider fairness metrics \"{}\" as one of the optimization objective or "
"considering whether \"{}\" influences \"{}\". If yes, it is suggested to "
"remove it from sensitive attributes list."

#: src/mvc/model_eval.py:177
msgid "model_eval_result_6"
msgstr ""
"The metric score(s) \"{}\" is low, the groups divided by sensitive "
"attribute \"{}\" may exsit bias. It is suggested to take these "
"metrics as the optimization objectives. Or considering whether "
"attribute \"{}\" has influences on \"{}\". If yes, please "
"remove it from sensitive attributes list."

#: src/mvc/model_eval.py:255
msgid "fairness_range"
msgstr "Fairness range"

#: src/mvc/model_eval.py:268 src/mvc/model_eval.py:326
msgid "group"
msgstr "group \"{}\""

#: src/mvc/model_eval.py:312
msgid "metrics_score"
msgstr "metric scores"

#: src/mvc/model_eval.py:373
msgid "model_eval_error_1"
msgstr ""
"A legitimate attribute must be selected to perform conditional group "
"equity analysis."

#: src/mvc/model_eval.py:376
msgid "model_eval_error_2"
msgstr "Legitimate attribute must be non-sensitive attribute."

#: static/info.js:2
msgid "sens_feature_info_1"
msgstr ""
"Sensitive attributes cannot influence labels, and some groups in "
"sensitive attributes may be discriminated / preferred."

#: static/info.js:6
msgid "legi_feature_info_1"
msgstr ""
"Legitimate attributes is non-sensitive attribute that could influence "
"labels"

#: static/info.js:11
msgid "data_g_fair_info_1"
msgstr ""
"Group fairness analysis: calculate the radio of positive rate between "
"groups and overall."

#: static/info.js:16
msgid "data_g_fair_info_4"
msgstr " 路  Defaut fairness range: "

#: static/info.js:17
msgid "data_g_fair_info_5"
msgstr "This metric refers to"

#: static/info.js:24
msgid "data_cg_fair_info_1"
msgstr ""
"Conditional group fairness analysis: calculate the group fairness under "
"subgroups divided by legitimate attributes."

#: static/info.js:29
msgid "data_cg_fair_info_4"
msgstr " 路  Defaut fairness range: "

#: static/info.js:30
msgid "data_cg_fair_info_5"
msgstr "This metric refers to"

#: static/info.js:37
msgid "data_i_fair_info_1"
msgstr ""
"Individual fairness analysis: prediction should be the same for any two "
"subjects with the exact same non-sensitive attributes."

#: static/info.js:38
msgid "data_i_fair_info_2"
msgstr "This metric refers to"

#: static/progress_bar.js:34 static/script.js:40
msgid "task_continue"
msgstr "Continue task"

#: static/script.js:34 static/script.js:41 templates/task_page.html:97
msgid "task_pause"
msgstr "Pause task"

#: static/script.js:35
msgid "task_pausing"
msgstr "Task_pausing ... please wait"

#: static/script.js:52
msgid "task_stopping"
msgstr "Task_stopping ... please wait"

#: templates/algo_cfg.html:5
msgid "algo_config"
msgstr "Algorithm configuration"

#: templates/algo_cfg.html:17 templates/data.html:22
#: templates/data_eval.html:27 templates/model_eval.html:27
#: templates/model_upload.html:17 templates/task_page.html:24
msgid "back"
msgstr "Return to start page"

#: templates/algo_cfg.html:18
msgid "algo_para_config"
msgstr "Configure algorithm parameters"

#: templates/algo_cfg.html:20 templates/data_eval.html:34
#: templates/model_eval.html:34
msgid "choose_sensitive_attributes"
msgstr "Select sensitive attributes"

#: templates/algo_cfg.html:34
msgid "accuracy_metric"
msgstr "Accuracy metric"

#: templates/algo_cfg.html:52
msgid "fairness_metric"
msgstr "Fairness metric"

#: templates/algo_cfg.html:66 templates/task_page.html:50
msgid "pop_size"
msgstr "Population size"

#: templates/algo_cfg.html:70
msgid "iter_time"
msgstr "Generation number"

#: templates/algo_cfg.html:77 templates/task_page.html:52
msgid "mo_optimazor"
msgstr "MOEA optimizer"

#: templates/algo_cfg.html:91
#, fuzzy
msgid "run_task"
msgstr "Run task"

#: templates/data.html:5
msgid "ml_model_eval "
msgstr "Machine learning model evaluation"

#: templates/data.html:26
msgid "dataset_selection "
msgstr "Dataset selection"

#: templates/data.html:27
msgid "data_info_1 "
msgstr ""
"Please click \"OK\" after selecting the data set. To upload a dataset, "
"click \"Upload dataset\" after selecting the data file."

#: templates/data.html:28
msgid "data_info_2 "
msgstr ""
"After confirming the selected dataset and checking the property list, "
"click \"Next step\"."

#: templates/data.html:42
msgid "yes"
msgstr "OK"

#: templates/data.html:46
msgid "download_data_temp "
msgstr "Download dataset template"

#: templates/data.html:51
msgid "select_data_file "
msgstr "Select dataset file"

#: templates/data.html:56
msgid "longterm_save_dataset "
msgstr "Longterm save datasets"

#: templates/data.html:59
msgid "dont_keep_dataset"
msgstr "Do not keep dataset"

#: templates/data.html:60
msgid "upload_dataset "
msgstr "Upload dataset"

#: templates/data.html:65
msgid "discrete_attribute"
msgstr "Categorical attribute(s)"

#: templates/data.html:71
msgid "continuous_attribute"
msgstr "Numerical attribute(s)"

#: templates/data.html:77
msgid "target_attribute "
msgstr "Target attribute / Label"

#: templates/data.html:84
msgid "next"
msgstr "Next step"

#: templates/data_eval.html:5
msgid "dataset_fairness_evaluation"
msgstr "Dataset fairness evaluation"

#: templates/data_eval.html:25
msgid "dataset"
msgstr "Dataset "

#: templates/data_eval.html:25 templates/model_eval.html:25
msgid "fairness_evaluation"
msgstr " fairness evaluation"

#: templates/data_eval.html:54 templates/model_eval.html:54
msgid "select_proper_attributes"
msgstr "Select legitimate attributes"

#: templates/footer.html:11
msgid "unit"
msgstr "Research Institute of Trustworthy Autonomous Systems (RITAS), SUSTech"

#: templates/footer.html:12
msgid "area"
msgstr "Nanshan District, Shenzhen, Guangdong Province, China"

#: templates/header.html:1 templates/index.html:5
msgid "platform_name"
msgstr ""
"FairerML: Machine Learning Fairness Evaluation and Suggestion Platform "
"(Demo v1)"

#: templates/index.html:12
msgid "intro_1"
msgstr ""
"This platform provides the function of analyzing the fairness problems "
"existing in machine learning data and models, and alleviating the "
"inequity of models by optimizing models with multi-objective algorithms. "
"Fairness in machine learning generally refers to [1]."

#: templates/index.html:13
msgid "intro_2"
msgstr ""
"People who are identical on non-sensitive attributes should have similar "
"predicted results (or labels). For example, for students with the same "
"grades, regardless of gender, the model should predict the same admission"
" outcome."

#: templates/index.html:14
msgid "intro_3"
msgstr ""
"The predicted results (or labels) between different groups should not "
"differ more than the differences between their non-sensitive "
"characteristics."

#: templates/index.html:15
msgid "intro_4"
msgstr ""
"Typically, there are certain characteristics recognized by law that do "
"not permit discrimination, and in the computer science literature, these "
"characteristics are often considered as \"protected\" or \"sensitive\" "
"attributes [2]."

#: templates/index.html:16
msgid "intro_5"
msgstr ""
"FairerML is capable of training Pareto model set considering "
"simultaneously accuracy and one or more fairness metrics with multi-"
"objective optimisation, specific algorithm implementation refers to [3]."

#: templates/index.html:30
msgid "finished_task"
msgstr "Finished tasks"

#: templates/index.html:35
msgid "running_task"
msgstr "Running tasks"

#: templates/index.html:44
msgid "func1"
msgstr "Fairness analysis on data"

#: templates/index.html:49
msgid "func2"
msgstr "Fairness analysis on ML models"

#: templates/index.html:54
msgid "func3"
msgstr "Training fairer ML models"

#: templates/model_eval.html:5
msgid "model_fairness_eval"
msgstr "Model fairness evaluation"

#: templates/model_eval.html:25
msgid "model "
msgstr "Model "

#: templates/model_upload.html:5
msgid "upload_ml_model"
msgstr "Upload machine learning model"

#: templates/model_upload.html:22
msgid "upload_model"
msgstr "Please upload model"

#: templates/model_upload.html:25
msgid "model_def_file_demo"
msgstr "Model definition file demo"

#: templates/model_upload.html:30
msgid "model_def_file_dec"
msgstr ""
"Please refer to the Pytorch model definition file (.py) and the saved "
"parameters (.pth or .plk) file. Saved parameters file must be exported by"
" \"torch.save(model.state_dict(),path)\". Model definition file must "
"contain a subclass of torch.nn.Module and a main() with no arguments, "
"this function will return a model instance."

#: templates/model_upload.html:32
msgid "download_model_template"
msgstr "Download model definition file template"

#: templates/model_upload.html:34
msgid "choose_model_structure"
msgstr "Choose model structure file"

#: templates/model_upload.html:36
msgid "choose_model_para"
msgstr "Choose model parameters file"

#: templates/model_upload.html:38
msgid "upload_model_eval"
msgstr "Upload model and evaluation model"

#: templates/task_page.html:5
msgid "task_status"
msgstr "Task status"

#: templates/task_page.html:26
msgid "optimization_process"
msgstr "Optimization process"

#: templates/task_page.html:28
msgid "task_end"
msgstr "Finished"

#: templates/task_page.html:30
msgid "task_running"
msgstr "Running"

#: templates/task_page.html:37
msgid "dataset_name"
msgstr "Dataset name"

#: templates/task_page.html:38
msgid "sensitive_attributes"
msgstr "Sensitive attribute(s)"

#: templates/task_page.html:49
msgid "optimization_obj"
msgstr "Optimization objectives"

#: templates/task_page.html:51
msgid "eval_num"
msgstr "Evolutionary evaluation"

#: templates/task_page.html:86
msgid "optimization_result"
msgstr "Optimization result for accuracy metric and fairness metric"

#: templates/task_page.html:96
msgid "task_stop"
msgstr "Stop task"

#: templates/task_page.html:101
msgid "download_models"
msgstr "Download models"

#~ msgid "data_eval_result_3"
#~ msgstr ""

#~ msgid "data_g_fair_info_2"
#~ msgstr " 路  If metric is low, this group may be discriminated"

#~ msgid "data_g_fair_info_3"
#~ msgstr " 路  If metric is high, this group may be preferred\""

#~ msgid "data_cg_fair_info_2"
#~ msgstr ""

#~ msgid "data_cg_fair_info_3"
#~ msgstr ""

